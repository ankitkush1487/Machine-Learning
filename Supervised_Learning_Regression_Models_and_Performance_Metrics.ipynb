{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP27bBEx3qDsmn6DbJhMFEG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ankitkush1487/Machine-Learning/blob/main/Supervised_Learning_Regression_Models_and_Performance_Metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose**\n",
        "\n",
        "Simple Linear Regression (SLR) is a statistical method that models the relationship between one independent (predictor) variable and one dependent (outcome) variable by fitting a straight line to the data. Its purpose is to quantify the relationship between the two variables, predict the value of the dependent variable based on the independent variable, and understand how changes in the independent variable affect the outcome.\n",
        "\n",
        "Purpose of Simple Linear Regression\n",
        "\n",
        "**Understanding the relationship:** SLR helps determine if a relationship exists between the two variables and how strong it is. For example, a researcher can see how closely test scores are related to hours spent studying.\n",
        "\n",
        "**Prediction:** Once the relationship is modeled, it can be used to predict the value of the dependent variable for a new value of the independent variable. For instance, if the model shows that for every additional hour a student studies, their test score increases by 4 points, you can predict their score based on the hours they study.\n",
        "\n",
        "**Quantifying the relationship:** The model provides a line with a slope and an intercept. The slope quantifies how much the dependent variable is expected to change for a one-unit increase in the independent variable. The intercept is the predicted value of the dependent variable when the independent variable is zero.\n",
        "Foundation for more advanced models: Although simple, SLR is a fundamental concept that serves as a building block for more complex regression techniques like multiple linear regression, which uses two or more independent variables"
      ],
      "metadata": {
        "id": "3tgby4CUb_Sy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 2: What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "\n",
        "Linearity\n",
        "\n",
        "The relationship between the independent variable (X) and the dependent variable (Y) is linear.\n",
        "\n",
        "Mathematically:\n",
        "\n",
        "ùëå= ùõΩ\n",
        "0\n",
        "+\n",
        "ùõΩ\n",
        "1\n",
        "ùëã\n",
        "+\n",
        "ùúÄ\n",
        "\n",
        "Y=Œ≤\n",
        "0\n",
        "+Œ≤\n",
        "1\n",
        "X+Œµ\n",
        "\n",
        "Independence of Errors\n",
        "\n",
        "The residuals (errors) are independent of each other.\n",
        "\n",
        "No autocorrelation should exist (important for time series data).\n",
        "\n",
        "Homoscedasticity\n",
        "\n",
        "The variance of residuals is constant across all levels of the independent variable.\n",
        "\n",
        "In other words, the spread of residuals should be uniform.\n",
        "\n",
        "Normality of Errors\n",
        "\n",
        "The residuals should be approximately normally distributed.\n",
        "\n",
        "This is important for hypothesis testing and confidence intervals.\n",
        "\n",
        "No Multicollinearity (for multiple regression)\n",
        "\n",
        "Although simple linear regression has only one predictor, this assumption applies when extending to multiple regression ‚Äî predictors should not be highly correlated.\n",
        "\n",
        "No Measurement Error in X\n",
        "\n",
        "The independent variable (X) is measured without error."
      ],
      "metadata": {
        "id": "WGRr--qucifI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 3: Write the mathematical equation for a simple linear regression model and explain each term.**\n",
        "\n",
        "The mathematical equation for a simple linear regression model is \\(Y=a+bX\\), where \\(Y\\) is the dependent variable, \\(X\\) is the independent variable, \\(a\\) is the y-intercept (the value of \\(Y\\) when \\(X\\) is 0), and \\(b\\) is the slope of the line, representing the change in \\(Y\\) for a one-unit increase in \\(X\\).\n",
        "\n",
        "Equation breakdown¬†\\(Y\\): The dependent variable (the outcome you are trying to predict).\\(X\\): The independent variable (the predictor variable).\\(a\\): The y-intercept. This is the value of \\(Y\\) when \\(X=0\\). It's where the regression line crosses the y-axis.\\(b\\): The slope. This represents the average change in the dependent variable (\\(Y\\)) for each one-unit increase in the independent variable (\\(X\\))."
      ],
      "metadata": {
        "id": "kfbGqn1sdfm_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 4: Provide a real-world example where simple linear regression can be applied.**\n",
        "\n",
        "A real-world example of simple linear regression is predicting a company's sales based on its advertising costs. By collecting data on past advertising expenses and corresponding sales figures, a company can use this simple model to understand the relationship between the two and forecast future sales based on a given advertising budget.\n",
        "\n",
        "Independent variable: Advertising cost. This is the variable that is manipulated or changed.\n",
        "\n",
        "Dependent variable: Sales. This is the variable that is being predicted or measured.\n",
        "\n",
        "Application: The model will produce an equation that can be used to estimate the sales that can be expected for a certain amount of money spent on advertising. For instance, if the analysis shows a positive relationship, it means that more advertising leads to more sales"
      ],
      "metadata": {
        "id": "MleQeB1Gdz5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 5: What is the method of least squares in linear regression?**\n",
        "\n",
        "\n",
        "The method of least squares in linear regression is a statistical technique used to find the best-fit line for a set of data points by minimizing the sum of the squares of the vertical distances (residuals) between the data points and the line.\n",
        "This is achieved by finding the line's slope and y-intercept that minimize this sum of squared errors, represented by the equation \\(S=\\sum (y_{i}-(ax_{i}+b))^{2}\\).\n",
        "\n",
        "¬†How it works¬†Calculate the error:\n",
        "\n",
        " For each data point \\((x_{i},y_{i})\\), the error (or residual, \\(e_{i}\\)) is the difference between the observed value (\\(y_{i}\\)) and the predicted value (\\(ax_{i}+b\\)) from the line.Square the errors: Each error (\\(e_{i}\\)) is squared to ensure that all values are positive and larger errors are penalized more heavily.\n",
        "\n",
        " Sum the squares: All the squared errors are summed up (\\(S=\\sum e_{i}^{2}\\)).\n",
        "\n",
        " Find the minimum: The method uses calculus to find the values for the slope (\\(a\\)) and y-intercept (\\(b\\)) that make this sum of squares (\\(S\\)) as small as possible, resulting in the line that best fits the data."
      ],
      "metadata": {
        "id": "uncDh1sJeFxx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 6: What is Logistic Regression? How does it differ from Linear Regression?**\n",
        "\n",
        "Logistic Regression predicts the probability of a categorical outcome, while Linear Regression predicts a continuous outcome. Key differences include the type of problem they solve (classification vs. regression), the output they produce (probability vs. continuous value), and the mathematical function they use (logistic/sigmoid vs. linear).\n",
        "\n",
        "Logistic Regression\n",
        "\n",
        "What it is: A statistical method for predicting a categorical outcome by modeling the probability of an event occurring. It uses a logistic or S-shaped curve to map the relationship between independent variables and the probability of the dependent variable.\n",
        "\n",
        "Use case: Classification problems where the output is a category, such as spam/not-spam, disease/no disease, or approving/denying a loan.\n",
        "\n",
        "Output: A probability score between 0 and 1, which is then used to classify the outcome.\n",
        "\n",
        "Method: Uses maximum likelihood estimation to find the best-fitting curve.\n",
        "\n",
        "Linear Regression\n",
        "\n",
        "What it is: A statistical method that models the relationship between a dependent variable and one or more independent variables as a straight line. It's used for regression problems where the outcome is a continuous numerical value.\n",
        "Use case: Regression problems where the output is a continuous value, such as predicting house prices, stock prices, or temperature.\n",
        "\n",
        "Output: A continuous value that can be any real number.\n",
        "Method: Uses ordinary least squares (OLS) to find the line that minimizes the difference between the predicted and actual values."
      ],
      "metadata": {
        "id": "Cndbenzgesj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 7: Name and briefly describe three common evaluation metrics for regression models.**\n",
        "\n",
        "Three common evaluation metrics for regression models are Mean Absolute Error (MAE), Mean Squared Error (MSE), and R-squared (\\(R^{2}\\)) score.\n",
        "\n",
        "\n",
        "1. Mean Absolute Error (MAE)¬†MAE measures the average magnitude of the errors (the absolute difference between the predicted and actual values).¬†Description: It is the average of the absolute differences between the actual observed values and the values predicted by the model.Interpretation: The result is in the same unit as the original target variable, which makes it easy to interpret (e.g., an MAE of 5 in a house price prediction model means the predictions are, on average, off by $5,000).Key Trait: MAE is less sensitive to outliers compared to MSE because it does not square the errors, giving all errors equal weight.\n",
        "\n",
        "2. Mean Squared Error (MSE)¬†MSE measures the average of the squared differences between the predicted and actual values.¬†Description: It is calculated by taking the average of the squared residuals (differences between actual and predicted values).Interpretation: A lower MSE value indicates a better fit. Because the errors are squared, the resulting unit is the square of the original unit, which can be less intuitive to interpret.Key Trait: MSE penalizes larger errors more heavily than smaller ones, making it sensitive to outliers. This makes it a good metric to use when large errors are particularly undesirable.\n",
        "\n",
        "3. R-squared (\\(R^{2}\\)) Score (Coefficient of Determination)¬†The \\(R^{2}\\) score provides a measure of how well the model explains the variability in the target variable.¬†Description: It quantifies the proportion of the variance in the dependent variable that is predictable from the independent variables.Interpretation: \\(R^{2}\\) ranges from 0 to 1, where 1 indicates a perfect fit (the model explains all the variability), and 0 indicates that the model does not explain any variance better than a simple mean model. A higher value generally indicates a better model fit.Key Trait: It is a relative metric that allows for comparing models trained on the same dataset. However, adding more independent variables can sometimes increase \\(R^{2}\\) even if the new features are irrelevant, which led to the development of the adjusted \\(R^{2}\\) metric\n"
      ],
      "metadata": {
        "id": "cAEv5eYzfH4D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 8: What is the purpose of the R-squared metric in regression analysis?**\n",
        "\n",
        "The purpose of the R-squared (coefficient of determination) metric is to indicate the proportion of variance in a dependent variable that is predictable from the independent variables in a regression model, essentially measuring the goodness of fit. A higher R-squared value (between 0 and 1) means the model explains more of the variability in the data, while a value of 0 means it explains none of the variability.\n",
        "\n",
        "Key purposes of R-squared¬†Measures goodness of fit:\n",
        "\n",
        " R-squared tells you how well the regression line fits the data points.Quantifies explanatory power: It shows the percentage of the dependent variable's variance that is explained by the independent variables in the model. For example, an R-squared of \\(0.76\\) means \\(76\\%\\) of the variance in the dependent variable is explained by the model.Indicates a better model: A higher R-squared value suggests that the model's predictions are closer to the actual data points.Allows for comparison: It can be used to compare different regression models, though it should be used in conjunction with other metrics.\n",
        "\n",
        " Important considerations¬†Not a measure of accuracy: A high R-squared does not guarantee the model is accurate or that the predictors are causing the changes in the dependent variable.Can be misleading: The R-squared value will always increase or stay the same when more variables are added to a model, even if those variables are not statistically significant.Context is key: What constitutes a \"good\" R-squared value varies depending on the field of study"
      ],
      "metadata": {
        "id": "MBrcMoQTfije"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.**\n",
        "**(Include your Python code and output in the code box below.)**\n"
      ],
      "metadata": {
        "id": "_4A6iyiDf5ca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Sample data\n",
        "# X should be a 2D array, even for a single feature\n",
        "X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).reshape(-1, 1)\n",
        "y = np.array([2, 4, 5, 4, 6, 7, 8, 9, 10, 12])\n",
        "\n",
        "# Create a Linear Regression model object\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the slope (coefficient) and intercept\n",
        "print(f\"Slope (Coefficient): {model.coef_[0]}\")\n",
        "print(f\"Intercept: {model.intercept_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YApFOYlgHIE",
        "outputId": "48d72764-a620-42fd-a3b4-f285dddde190"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 1.0000000000000002\n",
            "Intercept: 1.1999999999999993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question 10: How do you interpret the coefficients in a simple linear regression model?**\n",
        "\n",
        "\n",
        "In a simple linear regression model, the slope coefficient represents the estimated change in the dependent variable for a one-unit increase in the independent variable. The intercept coefficient is the predicted value of the dependent variable when the independent variable is zero, though this value may not be meaningful in all contexts. The sign of the slope coefficient indicates the direction of the relationship: positive for a positive correlation and negative for a negative correlation.\n",
        "\n",
        "**¬†Slope coefficient (the slope)**\n",
        "\n",
        "¬†Interpretation: For every one-unit increase in the independent variable, the dependent variable is predicted to increase or decrease by the value of the slope coefficient.Example: If a model predicts that for every one-year increase in education, a person's salary increases by \\(\\$2,000\\), the slope coefficient is \\(2,000\\).\n",
        "\n",
        "**Intercept coefficient (the y-intercept)¬†**\n",
        "\n",
        "Interpretation: The value of the dependent variable when the independent variable is zero.Example: In the equation for a car's stopping distance, the y-intercept might be a negative value, which is not practically meaningful as a distance cannot be negative.\n",
        "\n",
        "**¬†Sign of the coefficient¬†**\n",
        "Positive coefficient: A positive slope indicates a direct, positive relationship. As the independent variable increases, the dependent variable also tends to increase.Negative coefficient: A negative slope indicates an indirect, negative relationship. As the independent variable increases, the dependent variable tends to decrease."
      ],
      "metadata": {
        "id": "j3P31tnWgO89"
      }
    }
  ]
}